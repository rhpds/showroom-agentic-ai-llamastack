= Agent - LangGraph

You should have completed the modules called *Backend Setup* and *MCP* before attempting this module.  

This module focuses on the deployment of a backend and frontend - a web-based chat user interface frontend based on Node and a Python-based backend. 

There is a helm chart to deploy both the frontend and backend to keep things simple.

== Agent with Chat UI

Make sure you are in the correct directory

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
cd $HOME/fantaco-redhat-one-2026/
pwd
----

[.console-output]
[source,bash,subs=attributes+]
----
/home/lab-user/fantaco-redhat-one-2026
----


[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
helm install fantaco-agent ./helm/fantaco-agent
----

[.console-output]
[source,bash,subs=attributes+]
----
NAME: fantaco-agent
LAST DEPLOYED: Sun Dec 14 20:30:29 2025
NAMESPACE: agentic-user1
STATUS: deployed
REVISION: 1
TEST SUITE: None
----

This will deploy two new pods and a new route for the frontend UI. 

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
oc get pods
----

[.console-output]
[source,bash,subs=attributes+]
----
NAME                                           READY   STATUS    RESTARTS   AGE
fantaco-customer-main-7fd4ddb666-8nsx4         1/1     Running   0          74m
fantaco-finance-main-75ffddb44b-trf6p          1/1     Running   0          74m
langgraph-fastapi-596cfc9b57-bkzv4             1/1     Running   0          72s
llamastack-distribution-vllm-7d788bf4c-hbnbd   1/1     Running   0          152m
mcp-customer-6bd8bcfc7b-m8pdh                  1/1     Running   0          72m
mcp-finance-75bd497cfd-pvblv                   1/1     Running   0          72m
postgresql-customer-ff78dffdf-72w9l            1/1     Running   0          74m
postgresql-finance-689d97894f-5xz8d            1/1     Running   0          74m
simple-agent-chat-ui-6d7794dc6b-zk95v          1/1     Running   0          72s
----

A LangGraph Fast API backend as well as a chat UI as the two new pods. 

Get the URL to the Chat UI

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
export CHAT_URL=http://$(oc get routes -l app=simple-agent-chat-ui -o jsonpath="{range .items[*]}{.status.ingress[0].host}{end}")
echo $CHAT_URL
----

[.console-output]
[source,bash,subs=attributes+]
----
http://simple-agent-chat-ui-showroom-nn2ct-1-user1.apps.cluster-nn2ct.dynamic.redhatworkshops.io
----

And open in a new browser tab.

You can also view the whole architecture deployed in your namespace via the OpenShift Developer Console Topology view

image::topology.png[]

Now you can ask it questions interactively such as:

[.console-input]
[source,text,role="copypaste",subs=attributes+]
----
What is the capital of Italy?
----

image::chat_ui_1.png[]

[.console-output]
[source,text,subs=attributes+]
----
The tools available to me are designed for managing customer data, order history, invoices, and related tasks. They do not include functionality for retrieving general knowledge facts like the capital of Italy. You'll need to consult a geography resource or a general knowledge database for that information.
----


Try questions specific to the domain of the Agent thanks to the previously deployed and registered Customer and Finance MCP servers

[.console-input]
[source,text,role="copypaste",subs=attributes+]
----
Who are the customers?
----

image::chat_ui_2.png[]

In Terminal 1, check the logs of your Llama Stack instance to see what's going on under the hood:


[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
oc logs -f deploy/llamastack-distribution-vllm
----

Execute several other queries that combine customer and order data.

[.console-input]
[source,text,role="copypaste",subs=attributes+]
----
What invoices does customer LONEP have?
----

image::chat_ui_3.png[]

[.console-input]
[source,text,role="copypaste",subs=attributes+]
----
What is the status of order 6 for Fran Wilson?
----

image::chat_ui_4.png[]





