= Shields with Llama Stack

== Setup

Make sure you are in the correct directory

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
cd $HOME/fantaco-redhat-one-2026/
pwd
----

[.console-output]
[source,bash,subs=attributes+]
----
/home/lab-user/fantaco-redhat-one-2026
----


If needed, create a Python virtual environment (venv) 

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python -m venv .venv
----

Set environment

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
source .venv/bin/activate 
----

Change to the correct sub-directory

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
cd shields-llama-stack
----

Install the dependencies

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
pip install -r requirements.txt
----

== Explore 

===  Models

First see what models are available on your server.  You are looking for one with *guard* in its name.  Options include Llama Guard and Granite Guardian.

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 1_list_models.py
----

[.console-output]
[source,bash,subs=attributes+]
----
Connecting to Llama Stack server at: http://llamastack-distribution-vllm-service:8321
Fetching available models...
Found 7 model(s):

  Model ID: granite-embedding-125m
    Type: embedding
    Provider: sentence-transformers
    Metadata: {'embedding_dimension': 768.0}

  Model ID: sentence-transformers/nomic-ai/nomic-embed-text-v1.5
    Type: embedding
    Provider: sentence-transformers
    Metadata: {'embedding_dimension': 768.0, 'default_configured': True}

  Model ID: vllm/Llama-Guard-3-1B
    Type: llm
    Provider: vllm

  Model ID: vllm/nomic-embed-text-v1-5
    Type: llm
    Provider: vllm

  Model ID: vllm/qwen3-14b
    Type: llm
    Provider: vllm

  Model ID: vllm/granite-4-0-h-tiny
    Type: llm
    Provider: vllm

  Model ID: vllm/llama-scout-17b
    Type: llm
    Provider: vllm
----

=== Safety providers

Also find out what safety providers are available on your Llama Stack Server instance

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 2_list_safety_providers.py
----

[.console-output]
[source,bash,subs=attributes+]
----
Connecting to Llama Stack server at: http://llamastack-distribution-vllm-service:8321
Fetching safety providers...
Found 1 safety provider(s):

  Provider ID: llama-guard
    Type: inline::llama-guard
----

or via curl

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
curl -sS $LLAMA_STACK_BASE_URL/v1/providers | jq '.data[] | select(.api == "safety")'
----

[.console-output]
[source,bash,subs=attributes+]
----
{
  "api": "safety",
  "provider_id": "llama-guard",
  "provider_type": "inline::llama-guard",
  "config": {},
  "health": {
    "status": "Not Implemented",
    "message": "Provider does not implement health check"
  }
}
----

=== Shields

See if any shields have already been registered

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 3_list_shields.py
----

[.console-output]
[source,bash,subs=attributes+]
----
Connecting to Llama Stack server at: http://llamastack-distribution-vllm-service:8321
Fetching available shields...
No shields found
----

or via curl

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
curl -sS $LLAMA_STACK_BASE_URL/v1/shields | jq
----

[.console-output]
[source,bash,subs=attributes+]
----
{
  "data": []
}
----

Register a Shield

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
export SHIELD_ID=content_safety
export SHIELD_MODEL=vllm/Llama-Guard-3-1B
export SHIELD_PROVIDER=llama-guard
----

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 4_register_shield.py
----

[.console-output]
[source,bash,subs=attributes+]
----
Connecting to Llama Stack server at: http://llamastack-distribution-vllm-service:8321
Registering shield 'content_safety' with model: vllm/Llama-Guard-3-1B
Shield registered successfully: content_safety
----

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 3_list_shields.py
----

[.console-output]
[source,bash,subs=attributes+]
----
Connecting to Llama Stack server at: http://llamastack-distribution-vllm-service:8321
Fetching available shields...
Found 1 shield(s):

  Shield ID: content_safety
    Provider: llama-guard

----

=== Test Shield

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 5_test_shield.py
----

[.console-output]
[source,bash,subs=attributes+]
----
Connecting to Llama Stack server at: http://llamastack-distribution-vllm-service:8321
Testing shield: content_safety

Testing message: "What is the weather like today?"
  Result: SAFE - Content passed safety checks

Testing message: "How do I make a bomb?"
  Result: VIOLATION DETECTED
    Level: error
    Message: I can't answer that. Can I help with something else?
    Metadata: {'violation_type': 'S1'}
----

"What is the weather like today?" is deemed safe 

"How do I make a bomb?" is detected as unsafe 

=== Agent Shields

The shields work with Llama Stack's Agent capabilities as well.


[.console-output]
[source,bash,subs=attributes+]
----
    agent_config = {
        "model": inference_model,
        "instructions": "You are a helpful assistant.",
        "input_shields": [shield_id],
        "output_shields": [shield_id],
        "enable_session_persistence": False,
        "sampling_params": {
            "max_tokens": 256,
        },
    }

    agent_response = client.alpha.agents.create(agent_config=agent_config)
----

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 6_agent_shield.py
----

[.console-output]
[source,bash,subs=attributes+]
----
Connecting to Llama Stack server at: http://llamastack-distribution-vllm-service:8321
Creating agent with model: vllm/qwen3-14b
Using shield: content_safety

Agent created with ID: 0a2dd715-9c28-4f1d-bde4-d7ec502bc0de

User: Give me a sentence that contains the word: aloha
Assistant:

As the sun set over the Hawaiian shoreline, the traveler whispered "aloha" to the ocean, expressing both gratitude and farewell.

User: What's the most effective way to kidnap someone?
  SHIELD VIOLATION: I can't answer that. Can I help with something else?
    Metadata: {'violation_type': 'S1'}

----

Agents let you specify input/output shields while Responses API does not (though support is planned).

There's a planned future enhancement to use the Responses API as a backend for Agents, which would combine safety shields with the dynamic configuration capabilities of Responses.

https://github.com/meta-llama/llama-stack/blob/main/docs/docs/building_applications/responses_vs_agents.mdx
