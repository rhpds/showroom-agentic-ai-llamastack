= Agent

The agent includes a web-based chat user interface therefore we need both a backend and frontend.

You will need two terminals to make this work.


== Agent Backend: Terminal 1

Make sure you are in the correct directory

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
pwd
----

[.console-output]
[source,bash,subs=attributes+]
----
/home/lab-user/fantaco-redhat-one-2026/simple-agent-langgraph
----

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
python 9_langgraph_fastapi.py
----

[.console-output]
[source,bash,subs=attributes+]
----
2025-12-14 17:55:08,721 - __main__ - INFO - Configuration loaded:
2025-12-14 17:55:08,721 - __main__ - INFO -   Base URL: http://llamastack-distribution-vllm-service:8321
2025-12-14 17:55:08,722 - __main__ - INFO -   Model: vllm/qwen3-14b-gaudi
2025-12-14 17:55:08,722 - __main__ - INFO -   API Key: ***
2025-12-14 17:55:08,722 - __main__ - INFO -   FastAPI Host: 0.0.0.0
2025-12-14 17:55:08,722 - __main__ - INFO -   FastAPI Port: 8001
2025-12-14 17:55:09,426 - __main__ - INFO - Testing LLM connectivity...
2025-12-14 17:55:11,819 - httpx - INFO - HTTP Request: POST http://llamastack-distribution-vllm-service:8321/v1/openai/v1/responses "HTTP/1.1 200 OK"
2025-12-14 17:55:12,107 - __main__ - INFO - LLM connectivity test successful
INFO:     Started server process [561]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
----

== Agent Frontend: Terminal 2

The frontend uses *node* and *npm*

Make sure you are the correct directory

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
cd /home/lab-user/fantaco-redhat-one-2026/simple-agent-langgraph/simple-agent-chat-ui/
----

[.console-input]
[source,bash,role="copypaste",subs=attributes+]
----
export CHAT_UI_PORT=3001
export FASTAPI_URL=http://localhost:8001
----



